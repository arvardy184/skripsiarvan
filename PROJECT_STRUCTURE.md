# AccelPose - Complete Project Structure

## ğŸ“ Directory Tree

```
skripsiarvan/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ build.gradle.kts                    # Module-level Gradle config with dependencies
â”‚   â”‚
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main/
â”‚       â”‚   â”œâ”€â”€ AndroidManifest.xml         # App manifest with camera permissions
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ assets/                     # TensorFlow Lite models directory
â”‚       â”‚   â”‚   â”œâ”€â”€ README_MODELS.txt       # Model download instructions
â”‚       â”‚   â”‚   â”œâ”€â”€ movenet_lightning_int8.tflite      (download required)
â”‚       â”‚   â”‚   â””â”€â”€ blazepose_lite_fp16.tflite         (download required)
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ java/com/application/skripsiarvan/
â”‚       â”‚       â”‚
â”‚       â”‚       â”œâ”€â”€ MainActivity.kt         # Entry point with permission handling
â”‚       â”‚       â”‚
â”‚       â”‚       â”œâ”€â”€ domain/                 # Business Logic Layer
â”‚       â”‚       â”‚   â”œâ”€â”€ model/
â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ Keypoint.kt           # Single keypoint data class
â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ Person.kt             # Person with 17 keypoints
â”‚       â”‚       â”‚   â”‚   â””â”€â”€ ModelType.kt          # Enums for Model & Delegate types
â”‚       â”‚       â”‚   â”‚
â”‚       â”‚       â”‚   â””â”€â”€ detector/
â”‚       â”‚       â”‚       â””â”€â”€ PoseDetector.kt       # Strategy pattern interface
â”‚       â”‚       â”‚
â”‚       â”‚       â”œâ”€â”€ data/                   # Data Layer
â”‚       â”‚       â”‚   â”œâ”€â”€ ml/
â”‚       â”‚       â”‚   â”‚   â””â”€â”€ TFLiteHelper.kt       # TFLite interpreter & delegate manager
â”‚       â”‚       â”‚   â”‚
â”‚       â”‚       â”‚   â””â”€â”€ detector/
â”‚       â”‚       â”‚       â”œâ”€â”€ MoveNetDetector.kt    # MoveNet implementation
â”‚       â”‚       â”‚       â””â”€â”€ BlazePoseDetector.kt  # BlazePose implementation
â”‚       â”‚       â”‚
â”‚       â”‚       â”œâ”€â”€ presentation/           # UI Layer
â”‚       â”‚       â”‚   â”œâ”€â”€ viewmodel/
â”‚       â”‚       â”‚   â”‚   â””â”€â”€ PoseViewModel.kt      # State management & lifecycle
â”‚       â”‚       â”‚   â”‚
â”‚       â”‚       â”‚   â”œâ”€â”€ camera/
â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ CameraScreen.kt       # Main UI with controls & metrics
â”‚       â”‚       â”‚   â”‚   â””â”€â”€ PoseImageAnalyzer.kt  # CameraX analyzer with perf tracking
â”‚       â”‚       â”‚   â”‚
â”‚       â”‚       â”‚   â””â”€â”€ components/
â”‚       â”‚       â”‚       â””â”€â”€ PoseVisualization.kt  # Canvas drawing for skeleton
â”‚       â”‚       â”‚
â”‚       â”‚       â””â”€â”€ ui/theme/
â”‚       â”‚           â”œâ”€â”€ Color.kt
â”‚       â”‚           â”œâ”€â”€ Theme.kt
â”‚       â”‚           â””â”€â”€ Type.kt
â”‚       â”‚
â”‚       â”œâ”€â”€ androidTest/                    # Instrumentation tests
â”‚       â””â”€â”€ test/                           # Unit tests
â”‚
â”œâ”€â”€ build.gradle.kts                        # Project-level Gradle config
â”œâ”€â”€ settings.gradle.kts                     # Gradle settings
â”œâ”€â”€ gradle.properties                       # Gradle properties
â”œâ”€â”€ .gitignore                             # Git ignore rules (includes *.tflite)
â”‚
â”œâ”€â”€ README.md                              # Main project documentation
â””â”€â”€ PROJECT_STRUCTURE.md                   # This file

```

## ğŸ“ File Descriptions

### Core Application Files

#### `MainActivity.kt` (98 lines)
- **Purpose**: Entry point of the application
- **Key Features**:
  - Camera permission handling using ActivityResultContracts
  - Permission request UI with LaunchedEffect
  - Hosts CameraScreen when permission granted
- **Dependencies**: CameraScreen, Theme

---

### Domain Layer (Business Logic)

#### `domain/model/Keypoint.kt`
```kotlin
data class Keypoint(
    val x: Float,      // Normalized 0-1
    val y: Float,      // Normalized 0-1
    val score: Float,  // Confidence 0-1
    val label: String
)
```

#### `domain/model/Person.kt`
```kotlin
data class Person(
    val keypoints: List<Keypoint>,  // 17 COCO keypoints
    val score: Float
)

object BodyPart {
    // Constants for 17 COCO keypoints
    const val NOSE = 0
    const val LEFT_SHOULDER = 5
    // ... etc
}
```

#### `domain/model/ModelType.kt`
```kotlin
enum class ModelType(val displayName: String, val fileName: String)
enum class DelegateType(val displayName: String)
```

#### `domain/detector/PoseDetector.kt`
```kotlin
interface PoseDetector {
    fun detectPose(bitmap: Bitmap): Person?
    fun getInputSize(): Pair<Int, Int>
    fun close()
}
```

---

### Data Layer (Implementation)

#### `data/ml/TFLiteHelper.kt` (115 lines)
- **Purpose**: Manages TFLite interpreter and hardware delegates
- **Key Features**:
  - Loads models from assets folder
  - Initializes interpreter with selected delegate
  - GPU compatibility check using `CompatibilityList`
  - Automatic fallback to CPU if GPU unavailable
  - Proper resource cleanup

**Delegate Initialization**:
```kotlin
DelegateType.CPU   -> options.setUseXNNPACK(true)
DelegateType.GPU   -> options.addDelegate(GpuDelegate(delegateOptions))
DelegateType.NNAPI -> options.addDelegate(NnApiDelegate())
```

#### `data/detector/MoveNetDetector.kt` (92 lines)
- **Purpose**: MoveNet Lightning model implementation
- **Input**: 192x192 RGB image
- **Output**: [1, 1, 17, 3] tensor (y, x, score)
- **Features**:
  - Image preprocessing with normalization
  - Confidence threshold filtering (0.3)
  - Returns Person with 17 keypoints

#### `data/detector/BlazePoseDetector.kt` (105 lines)
- **Purpose**: MediaPipe BlazePose model implementation
- **Input**: 256x256 RGB image
- **Output**: [1, 33, 5] tensor (33 landmarks mapped to 17 COCO)
- **Features**:
  - BlazePose to COCO keypoint mapping
  - Visibility score as confidence
  - Higher confidence threshold (0.5)

---

### Presentation Layer (UI)

#### `presentation/viewmodel/PoseViewModel.kt` (148 lines)
- **Purpose**: Manages app state and model lifecycle
- **State Management**:
  ```kotlin
  data class PoseUiState(
      val selectedModel: ModelType,
      val selectedDelegate: DelegateType,
      val detectedPerson: Person?,
      val inferenceTime: Long,
      val fps: Float,
      val isInitialized: Boolean,
      val errorMessage: String?
  )
  ```
- **Key Functions**:
  - `initializeDetector()`: Creates new detector with selected config
  - `selectModel()`: Switches model and reinitializes
  - `selectDelegate()`: Switches delegate and reinitializes
  - `updateResults()`: Updates metrics from camera analyzer

#### `presentation/camera/CameraScreen.kt` (257 lines)
- **Purpose**: Main UI with camera preview and controls
- **Components**:
  - **CameraX Preview**: AndroidView with PreviewView
  - **Image Analysis**: Real-time pose detection
  - **Control Panel**: Model/delegate dropdowns + metrics
  - **Pose Overlay**: Visualization on top of camera

- **Composables**:
  - `CameraScreen()`: Main composable
  - `ControlPanel()`: Bottom card with controls
  - `DropdownSelector<T>()`: Generic dropdown for model/delegate
  - `MetricsDisplay()`: Inference time & FPS display
  - `DeviceInfoDisplay()`: Device model & Android version

#### `presentation/camera/PoseImageAnalyzer.kt` (102 lines)
- **Purpose**: CameraX ImageAnalysis.Analyzer for real-time inference
- **Process Flow**:
  1. Convert `ImageProxy` to `Bitmap`
  2. Rotate based on device orientation
  3. Resize to model input size
  4. Run inference (with timing)
  5. Calculate FPS
  6. Send results to ViewModel

- **Performance Tracking**:
  ```kotlin
  val startTime = System.nanoTime()
  val person = poseDetector.detectPose(bitmap)
  val inferenceTime = (System.nanoTime() - startTime) / 1_000_000L
  ```

#### `presentation/components/PoseVisualization.kt` (127 lines)
- **Purpose**: Draws pose skeleton on Canvas
- **Features**:
  - Draws 16 bone connections (lines)
  - Draws 17 joint keypoints (circles)
  - Confidence-based filtering (> 0.3)
  - Green lines, red circles
  - Scales to view dimensions

---

## ğŸ”„ Data Flow

```
User Action (Select Model/Delegate)
    â†“
ViewModel.selectModel() / selectDelegate()
    â†“
ViewModel.initializeDetector()
    â†“
TFLiteHelper.initializeInterpreter()
    â†“
Create MoveNetDetector / BlazePoseDetector
    â†“
Camera Frame Available
    â†“
PoseImageAnalyzer.analyze()
    â†“
PoseDetector.detectPose()
    â†“
ViewModel.updateResults()
    â†“
UI State Update (Compose Recomposition)
    â†“
CameraScreen displays metrics + PoseVisualization
```

## ğŸ“Š Key Metrics

### Inference Time Measurement
```kotlin
// Start timing before inference
val startTime = System.nanoTime()

// Run inference
val person = poseDetector.detectPose(bitmap)

// Calculate elapsed time in milliseconds
val inferenceTime = (System.nanoTime() - startTime) / 1_000_000L
```

### FPS Calculation
```kotlin
frameCount++
val currentTime = System.currentTimeMillis()
val elapsedTime = currentTime - lastFpsTimestamp

if (elapsedTime >= 1000) { // Update every second
    currentFps = (frameCount * 1000f) / elapsedTime
    frameCount = 0
    lastFpsTimestamp = currentTime
}
```

## ğŸ¨ UI Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    â”‚
â”‚        Camera Preview              â”‚
â”‚         (with Pose Overlay)        â”‚
â”‚                                    â”‚
â”‚                                    â”‚
â”‚                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AccelPose - Performance Benchmark â”‚
â”‚                                    â”‚
â”‚  Model: [MoveNet Lightning â–¼]     â”‚
â”‚  Accelerator: [CPU (XNNPACK) â–¼]   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  Inference: 25 ms    FPS: 35.2    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  Device: Samsung Galaxy S21        â”‚
â”‚  Android 13 (API 33)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Testing Strategy

### Unit Tests (Recommended)
- `TFLiteHelperTest`: Test delegate initialization
- `MoveNetDetectorTest`: Test output parsing
- `PoseViewModelTest`: Test state management

### Integration Tests (Recommended)
- Camera permission flow
- Model switching without crashes
- Delegate switching performance

### Manual Testing Checklist
- [ ] Camera permission granted/denied
- [ ] MoveNet model loads successfully
- [ ] BlazePose model loads successfully
- [ ] CPU delegate works
- [ ] GPU delegate works (or falls back to CPU)
- [ ] NNAPI delegate works
- [ ] Pose visualization renders correctly
- [ ] Metrics update in real-time
- [ ] App handles rotation gracefully

## ğŸ”§ Build Commands

```bash
# Clean build
./gradlew clean

# Debug APK
./gradlew assembleDebug

# Release APK (unsigned)
./gradlew assembleRelease

# Install on device
./gradlew installDebug

# Run tests
./gradlew test
./gradlew connectedAndroidTest
```

## ğŸ“¦ APK Size Optimization

Current size (estimated): ~50MB (with TFLite models)

**To reduce size**:
- Use INT8 quantized models
- Enable ProGuard/R8 in release builds
- Use model compression
- Split APKs by ABI

## ğŸš€ Future Enhancements

1. **Export Metrics**: CSV/JSON export for analysis
2. **Batch Testing**: Automated tests across configurations
3. **More Models**: YOLOv8-Pose, EfficientPose
4. **Video Input**: Test on recorded videos
5. **Graph Visualization**: Real-time performance graphs
6. **Multi-person Detection**: Support multiple people
7. **Custom Model Upload**: Load models at runtime

---

**Total Lines of Code**: ~1200+ lines (excluding tests and theme files)

**Last Updated**: December 2024
